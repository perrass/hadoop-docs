# Blog and Projects

Contents:

1. Books/Courses Notes
2. Papers Notes
3. Source Code Notes
4. Summary

#### Blog

The process of summary: **Statisitcal Machine Learning**

1. Linear Regression -> Logistic Regression -> Generalized Linear Model
2. Regularization: Ridge -> Lasso -> Elastic Net
3. Optimizer (First-order methods): Gradient -> Subgradient -> Proximal
4. Loss: GLM, Huber, Hinge, Cost-sensitive
5. Kernels: Lagrange, Duality, L1VM, L2VM, RVM, SVM, GP
6. Trees: Trees, Random Forest, AdaBoost, GBDT, XGBoost, Cost-senstive GBDT
7. Latent Models: PCA, ICA, SVD, EM, GMM, LDA, Clustering
8. PGM: DGM, UDM, MC, HMM, MCMC

The process of summary: **Deep Learning**

1. Neural Network: Gradient, Backpropagation
2. CNN: LaNet, AlexNet, VGG, GoogleNet, ResNet
3. RNN/LSTM: charRNN, Word2vec, Seq2Seq
4. GAN: GAN, DCGAN
5. RL: DQN
6. Tech: Dropout, BN, ReLU

#### Projects: Libs

Python: 通过几行代码可以自动对比模型结果

能想到的亮点: 

1. 更多的Optimizer
2. 更偏向机器学习的模型
3. Auto Derivatives
4. 计算图的架构

The modual of libs:

1. Model
2. Optimizer
3. Auto Derivative
4. Visualization
5. Data Preprocessing

C++/Spark: 实现部分功能

#### Projects: CTR Prediction

1. LR/MLR/GBDT/FFM
2. 做特征

#### Projects: Recommendation System

1. Item-CF, User-CF
2. Combine CNN/RNN

#### Projects: Image Classification

1. CNN Recoding
2. Image augmentation

#### Projects: CarND related

